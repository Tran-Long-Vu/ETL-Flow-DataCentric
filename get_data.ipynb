{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\n",
    "    \"kong-access-\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"metricbeat-\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                            \"query_string\": {\n",
    "                                \"query\": \"cee25daa-3fd9-441b-af33-8211e3649f3e\",\n",
    "                                \"default_operator\": \"AND\"\n",
    "                            }\n",
    "                        },\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"traces-apm\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"apm-\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"logs-apm\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"metrics-apm\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 17%|█▋        | 1/6 [00:04<00:20,  4.13s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 33%|███▎      | 2/6 [00:05<00:10,  2.72s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 50%|█████     | 3/6 [00:12<00:12,  4.28s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 67%|██████▋   | 4/6 [00:13<00:06,  3.03s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 83%|████████▎ | 5/6 [00:37<00:10, 10.79s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "100%|██████████| 6/6 [00:40<00:00,  6.74s/it]\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://116.101.122.180:5200/{index}*/_search\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": \"ApiKey\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "index_arr = [\"kong-access-\", \"metricbeat-\", \"traces-apm\", \"apm-\", \"logs-apm\", \"metrics-apm\"]\n",
    "\n",
    "for index in tqdm(index_arr):\n",
    "    url = base_url.format(index=index)\n",
    "    data = {\n",
    "        \"from\": 0,\n",
    "        \"size\": 500,\n",
    "        \"query\": queries[f\"{index}\"],\n",
    "        \"sort\": [\n",
    "            {\n",
    "                \"@timestamp\": {\n",
    "                    \"order\": \"asc\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    response = requests.get(\n",
    "        url, headers=headers,\n",
    "        json=data, verify=False\n",
    "    )\n",
    "    data = response.json()\n",
    "    with open(f\"./logs/{index}.json\", \"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Timestamp  \\\n",
      "0  2025-01-02T00:00:10.788Z   \n",
      "1  2025-01-02T00:00:14.668Z   \n",
      "2  2025-01-02T00:00:16.213Z   \n",
      "3  2025-01-02T00:00:21.259Z   \n",
      "4  2025-01-02T00:00:33.765Z   \n",
      "5  2025-01-02T00:01:15.794Z   \n",
      "6  2025-01-02T00:01:19.674Z   \n",
      "7  2025-01-02T00:01:21.216Z   \n",
      "8  2025-01-02T00:01:26.265Z   \n",
      "9  2025-01-02T00:02:20.801Z   \n",
      "\n",
      "                                             Message  \\\n",
      "0  [s1|connecting...] Protocol initialization req...   \n",
      "1  [s1|connecting...] Protocol initialization req...   \n",
      "2  [s0|connecting...] Protocol initialization req...   \n",
      "3  [s0|connecting...] Protocol initialization req...   \n",
      "4  unexpected end of stream on https://open.camer...   \n",
      "5  [s1|connecting...] Protocol initialization req...   \n",
      "6  [s1|connecting...] Protocol initialization req...   \n",
      "7  [s0|connecting...] Protocol initialization req...   \n",
      "8  [s0|connecting...] Protocol initialization req...   \n",
      "9  [s1|connecting...] Protocol initialization req...   \n",
      "\n",
      "                                          Error code  \\\n",
      "0  com.datastax.oss.driver.api.core.connection.Co...   \n",
      "1  com.datastax.oss.driver.api.core.connection.Co...   \n",
      "2  com.datastax.oss.driver.api.core.connection.Co...   \n",
      "3  com.datastax.oss.driver.api.core.connection.Co...   \n",
      "4                                java.io.IOException   \n",
      "5  com.datastax.oss.driver.api.core.connection.Co...   \n",
      "6  com.datastax.oss.driver.api.core.connection.Co...   \n",
      "7  com.datastax.oss.driver.api.core.connection.Co...   \n",
      "8  com.datastax.oss.driver.api.core.connection.Co...   \n",
      "9  com.datastax.oss.driver.api.core.connection.Co...   \n",
      "\n",
      "                                         Error cause  \n",
      "0  [s1|connecting...] Protocol initialization req...  \n",
      "1  [s1|connecting...] Protocol initialization req...  \n",
      "2  [s0|connecting...] Protocol initialization req...  \n",
      "3  [s0|connecting...] Protocol initialization req...  \n",
      "4  unexpected end of stream on https://open.camer...  \n",
      "5  [s1|connecting...] Protocol initialization req...  \n",
      "6  [s1|connecting...] Protocol initialization req...  \n",
      "7  [s0|connecting...] Protocol initialization req...  \n",
      "8  [s0|connecting...] Protocol initialization req...  \n",
      "9  [s1|connecting...] Protocol initialization req...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# LOGS \n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "with open('/Users/longcaca/Downloads/example/ETL-Flow-DataCentric/logs/logs-apm.json', 'r') as file:  # Replace with your actual file path\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extracting relevant fields from the nested structure\n",
    "extracted_data = []\n",
    "\n",
    "for hit in data['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    error_info = source.get('error', {})\n",
    "    stacktrace = error_info.get('stacktrace', [])\n",
    "    \n",
    "    # Prepare a dictionary for each record\n",
    "    record = {\n",
    "        'Timestamp': source.get('@timestamp', None),\n",
    "        'Message': source.get('message', ''),\n",
    "        # 'WARN message': '',  # Assuming WARD message is not present in the provided structure\n",
    "        # 'Stack trace': '\\n'.join([f\"{item['classname']} - {item['filename']}:{item['line']['number']} - {item['function']}\" for item in stacktrace]),\n",
    "        # 'Error code': error_info.get('type', ''),  # Assuming type as Error code\n",
    "        'Error code': error_info.get('exception', [{}])[0].get('type', ''),  # Get first exception message as Error cause\n",
    "        'Error cause': error_info.get('exception', [{}])[0].get('message', '')  # Get first exception message as Error cause\n",
    "    }\n",
    "    extracted_data.append(record)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Print the first 10 rows of the DataFrame\n",
    "print(df.head(10))\n",
    "df.to_csv('/Users/longcaca/Downloads/example/ETL-Flow-DataCentric/logs.csv' , index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Timestamp         transaction_name  transaction_duration  \\\n",
      "0  2025-01-02T00:00:00.092Z             ping dummydb                   624   \n",
      "1  2025-01-02T00:00:01.219Z             ping dummydb                   499   \n",
      "2  2025-01-02T00:00:01.290Z  GET /actuator/health/**                  1173   \n",
      "3  2025-01-02T00:00:01.290Z  GET /actuator/health/**                  1150   \n",
      "4  2025-01-02T00:00:02.004Z                      GET                  1659   \n",
      "5  2025-01-02T00:00:02.004Z                                              0   \n",
      "6  2025-01-02T00:00:02.126Z                     POST                  1144   \n",
      "7  2025-01-02T00:00:02.472Z             ping dummydb                   392   \n",
      "8  2025-01-02T00:00:03.403Z                     POST                  1456   \n",
      "9  2025-01-02T00:00:03.869Z                      GET                  1243   \n",
      "\n",
      "     transaction_id transaction_type     span_name  span_duration  \\\n",
      "0  58265d8827bec8c9          unknown                            0   \n",
      "1  8f5f76a935871345          unknown                            0   \n",
      "2  60f07b92ca4f9622          unknown                            0   \n",
      "3  6860c709b6154d77          unknown                            0   \n",
      "4  151554d973c7a0f5          request                            0   \n",
      "5                                     play.request            169   \n",
      "6  8476f19bce4c7a23          unknown                            0   \n",
      "7  cb0a27de8b6f161e          unknown                            0   \n",
      "8  123dc8bd7f5a6692          unknown                            0   \n",
      "9  b34d019565ed3c2f          unknown                            0   \n",
      "\n",
      "  span_subtype span_id  \n",
      "0                       \n",
      "1                       \n",
      "2                       \n",
      "3                       \n",
      "4                       \n",
      "5     internal     app  \n",
      "6                       \n",
      "7                       \n",
      "8                       \n",
      "9                       \n"
     ]
    }
   ],
   "source": [
    "# TRACES\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('/Users/longcaca/Downloads/example/ETL-Flow-DataCentric/logs/traces-apm.json', 'r') as file:  # Replace with your actual file path\n",
    "    data = json.load(file)\n",
    "\n",
    "# Prepare a list to hold the extracted records\n",
    "extracted_data = []\n",
    "\n",
    "# Iterate through each hit in the JSON data\n",
    "for hit in data['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    \n",
    "    # Extract relevant fields\n",
    "    transaction = source.get('transaction', {})\n",
    "    \n",
    "    # Ensure duration is accessed correctly and converted to seconds\n",
    "    duration_us = transaction.get('duration', {}).get('us', 0)  # Default to 0 if not found\n",
    "    \n",
    "    record = { #\n",
    "        'Timestamp': source.get('@timestamp', None),\n",
    "        \n",
    "        'transaction_name': transaction.get('name', ''),\n",
    "        'transaction_duration': duration_us,\n",
    "        'transaction_id': transaction.get('id', ''),\n",
    "        'transaction_type': transaction.get('type', ''),\n",
    "        \n",
    "        'span_name': source.get('span', {}).get('name', ''),\n",
    "        'span_duration': source.get('span', {}).get('duration', {}).get('us', 0),\n",
    "        'span_subtype': source.get('span', {}).get('subtype', ''),\n",
    "        'span_id': source.get('span', {}).get('id', ''),\n",
    "        'span_id': source.get('span', {}).get('type', ''),\n",
    "    }\n",
    "    \n",
    "    extracted_data.append(record)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Print the first 10 rows of the DataFrame\n",
    "print(df.head(10))\n",
    "df.to_csv('/Users/longcaca/Downloads/example/ETL-Flow-DataCentric/traces.csv'  ,  index = False )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Timestamp  System CPU Usage  Process CPU Usage  \\\n",
      "0    2025-01-02T00:00:00.000Z               NaN                NaN   \n",
      "1    2025-01-02T00:00:00.000Z               NaN                NaN   \n",
      "2    2025-01-02T00:00:00.000Z               NaN                NaN   \n",
      "3    2025-01-02T00:00:00.000Z               NaN                NaN   \n",
      "4    2025-01-02T00:00:00.000Z               NaN                NaN   \n",
      "..                        ...               ...                ...   \n",
      "495  2025-01-02T00:00:06.006Z               NaN                NaN   \n",
      "496  2025-01-02T00:00:06.006Z               NaN                NaN   \n",
      "497  2025-01-02T00:00:06.006Z               NaN                NaN   \n",
      "498  2025-01-02T00:00:06.006Z               NaN                NaN   \n",
      "499  2025-01-02T00:00:06.006Z               NaN                NaN   \n",
      "\n",
      "     System CPU Count  jvm_system_cpu_load_1m  jvm_cpu_utilization  \\\n",
      "0                 NaN                     NaN                  NaN   \n",
      "1                 NaN                     NaN                  NaN   \n",
      "2                 NaN                     NaN                  NaN   \n",
      "3                 NaN                     NaN                  NaN   \n",
      "4                 NaN                     NaN                  NaN   \n",
      "..                ...                     ...                  ...   \n",
      "495               NaN                     NaN                  NaN   \n",
      "496               NaN                     NaN                  NaN   \n",
      "497               NaN                     NaN                  NaN   \n",
      "498               NaN                     NaN                  NaN   \n",
      "499               NaN                     NaN                  NaN   \n",
      "\n",
      "     jvm_system_cpu_utilization  jvm.memory.committed  jvm.memory.max  \\\n",
      "0                           NaN                   NaN             NaN   \n",
      "1                           NaN                   NaN             NaN   \n",
      "2                           NaN                   NaN             NaN   \n",
      "3                           NaN                   NaN             NaN   \n",
      "4                           NaN                   NaN             NaN   \n",
      "..                          ...                   ...             ...   \n",
      "495                         NaN                   NaN             NaN   \n",
      "496                         NaN                   NaN             NaN   \n",
      "497                         NaN                   NaN             NaN   \n",
      "498                         NaN                   NaN             NaN   \n",
      "499                         NaN                   NaN             NaN   \n",
      "\n",
      "     jvm.memory.used  ...  process.runtime.jvm.memory.init  \\\n",
      "0                NaN  ...                              NaN   \n",
      "1                NaN  ...                              NaN   \n",
      "2                NaN  ...                              NaN   \n",
      "3                NaN  ...                              NaN   \n",
      "4                NaN  ...                              NaN   \n",
      "..               ...  ...                              ...   \n",
      "495              NaN  ...                              NaN   \n",
      "496              NaN  ...                              NaN   \n",
      "497              NaN  ...                              NaN   \n",
      "498              NaN  ...                              NaN   \n",
      "499              NaN  ...                              NaN   \n",
      "\n",
      "     process.runtime.jvm.memory.limit  process.runtime.jvm.memory.usage  \\\n",
      "0                                 NaN                               NaN   \n",
      "1                                 NaN                               NaN   \n",
      "2                                 NaN                               NaN   \n",
      "3                                 NaN                               NaN   \n",
      "4                                 NaN                               NaN   \n",
      "..                                ...                               ...   \n",
      "495                               NaN                               NaN   \n",
      "496                               NaN                               NaN   \n",
      "497                               NaN                               NaN   \n",
      "498                               NaN                               NaN   \n",
      "499                               NaN                               NaN   \n",
      "\n",
      "     process.runtime.jvm.memory.committed  \\\n",
      "0                                     NaN   \n",
      "1                                     NaN   \n",
      "2                                     NaN   \n",
      "3                                     NaN   \n",
      "4                                     NaN   \n",
      "..                                    ...   \n",
      "495                                   NaN   \n",
      "496                                   NaN   \n",
      "497                                   NaN   \n",
      "498                                   NaN   \n",
      "499                                   NaN   \n",
      "\n",
      "     process.runtime.jvm.memory.usage_after_last_gc  \\\n",
      "0                                               NaN   \n",
      "1                                               NaN   \n",
      "2                                               NaN   \n",
      "3                                               NaN   \n",
      "4                                               NaN   \n",
      "..                                              ...   \n",
      "495                                             NaN   \n",
      "496                                             NaN   \n",
      "497                                             NaN   \n",
      "498                                             NaN   \n",
      "499                                             NaN   \n",
      "\n",
      "     system.memory.utilization  system.memory.usage  Latency  Error Rate  \\\n",
      "0                          NaN                  NaN   2655.0        None   \n",
      "1                          NaN                  NaN    627.0        None   \n",
      "2                          NaN                  NaN    567.0        None   \n",
      "3                          NaN                  NaN   1247.0        None   \n",
      "4                          NaN                  NaN   1663.0    HTTP 4xx   \n",
      "..                         ...                  ...      ...         ...   \n",
      "495                        NaN                  NaN      NaN        None   \n",
      "496                        NaN                  NaN      NaN        None   \n",
      "497                        NaN                  NaN      NaN        None   \n",
      "498                        NaN                  NaN      NaN        None   \n",
      "499                        NaN                  NaN      NaN        None   \n",
      "\n",
      "     Number of Requests  \n",
      "0                     1  \n",
      "1                     2  \n",
      "2                     1  \n",
      "3                     1  \n",
      "4                     1  \n",
      "..                  ...  \n",
      "495                   0  \n",
      "496                   0  \n",
      "497                   0  \n",
      "498                   0  \n",
      "499                   0  \n",
      "\n",
      "[500 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('/Users/longcaca/Downloads/example/ETL-Flow-DataCentric/logs/metrics-apm.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extracting relevant information from the JSON structure\n",
    "# Assuming 'hits' contains the relevant metrics\n",
    "hits = data['hits']['hits']\n",
    "\n",
    "# Create a list to store extracted records\n",
    "extracted_data = []\n",
    "\n",
    "for hit in hits:\n",
    "    source = hit['_source']\n",
    "    transaction = source.get('transaction', {})\n",
    "    \n",
    "    # Extracting relevant fields\n",
    "    record = {\n",
    "        # Timestamp\n",
    "        'Timestamp': source.get('@timestamp', None),  # Adjust based on actual field names in your JSON\n",
    "        # CPU\n",
    "        'System CPU Usage': source.get('system.cpu.usage', None),  # Adjust based on actual field names in your JSON\n",
    "        'Process CPU Usage': source.get('process.cpu.usage', None),  # Adjust based on actual field names in your JSON\n",
    "        'System CPU Count': source.get('system.cpu.count', None),  # Adjust based on actual field names in your JSON\n",
    "        \n",
    "        'jvm_system_cpu_load_1m': source.get('process.runtime.jvm.system.cpu.load_1m', None),  # Adjust based on actual field names in your JSON\n",
    "        'jvm_cpu_utilization': source.get('process.runtime.jvm.cpu.utilization', None),  # Adjust based on actual field names in your JSON\n",
    "        'jvm_system_cpu_utilization': source.get('process.runtime.jvm.system.cpu.utilization', None),  # Adjust based on actual field names in your JSON\n",
    "        \n",
    "        # Memory\n",
    "        \n",
    "        'jvm.memory.committed': source.get('jvm.memory.committed', None),  # Adjust based on actual field names in your JSON\n",
    "        'jvm.memory.max': source.get('jvm.memory.max', None),  # Adjust based on actual field names in your JSON\n",
    "        'jvm.memory.used': source.get('jvm.memory.used', None),  # Adjust based on actual field names in your JSON\n",
    "        \n",
    "        'jvm.buffer.memory.used': source.get('jvm.buffer.memory.used', None),  \n",
    "        'jvm.memory.usage.after.gc': source.get('jvm.memory.usage.after.gc', None),  # Adjust based on actual field names in your JSON\n",
    "        'jvm.gc.memory.allocated': source.get('jvm.gc.memory.allocated', None),  # Adjust based on actual field names in your JSON\n",
    "        'jvm.gc.memory.promoted': source.get('jvm.gc.memory.promoted', None),  # Adjust based on actual field names in your JSON\n",
    "    \n",
    "        'process.runtime.jvm.memory.init': source.get('process.runtime.jvm.memory.init', None),  # Adjust based on actual field names in your JSON\n",
    "        'process.runtime.jvm.memory.limit': source.get('process.runtime.jvm.memory.limit', None),  # Adjust based on actual field names in your JSON\n",
    "        'process.runtime.jvm.memory.usage': source.get('process.runtime.jvm.memory.usage', None),  # Adjust based on actual field names in your JSON\n",
    "        'process.runtime.jvm.memory.committed': source.get('process.runtime.jvm.memory.committed', None),  # Adjust based on actual field names in your JSON\n",
    "        'process.runtime.jvm.memory.usage_after_last_gc': source.get('process.runtime.jvm.memory.usage_after_last_gc', None),  # Adjust based on actual field names in your JSON\n",
    "        \n",
    "        'system.memory.utilization': source.get('system.memory.utilization', None),  # Adjust based on actual field names in your JSON\n",
    "        'system.memory.usage': source.get('system.memory.usage', None),  # Adjust based on actual field names in your JSON\n",
    "        \n",
    "        'Latency': transaction.get('duration.histogram', {}).get('values', [None])[0],  # First value as latency\n",
    "        'Error Rate': transaction.get('result', None),  # Adjust based on actual error rate representation\n",
    "        'Number of Requests': source.get('_doc_count', 0)  # Total document count as number of requests\n",
    "    }\n",
    "    \n",
    "    extracted_data.append(record)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "df.to_csv('/Users/longcaca/Downloads/example/ETL-Flow-DataCentric/metrics.csv'  ,  index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib import request\n",
    " # from urllib.request\n",
    "request.urlopen('https://google.com').getcode()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
