{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = {\n",
    "    \"kong-access-\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"metricbeat-\": {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                            \"query_string\": {\n",
    "                                \"query\": \"cee25daa-3fd9-441b-af33-8211e3649f3e\",\n",
    "                                \"default_operator\": \"AND\"\n",
    "                            }\n",
    "                        },\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"traces-apm\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"apm-\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"logs-apm\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"metrics-apm\":{\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": \"2025-01-02T00:00:00.000Z\",\n",
    "                            \"lte\": \"2025-01-03T00:00:00.000Z\",\n",
    "                            \"format\": \"strict_date_optional_time\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 17%|█▋        | 1/6 [00:04<00:20,  4.13s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 33%|███▎      | 2/6 [00:05<00:10,  2.72s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 50%|█████     | 3/6 [00:12<00:12,  4.28s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 67%|██████▋   | 4/6 [00:13<00:06,  3.03s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      " 83%|████████▎ | 5/6 [00:37<00:10, 10.79s/it]/home/aiteam/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py:1068: InsecureRequestWarning: Unverified HTTPS request is being made to host '116.101.122.180'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n",
      "100%|██████████| 6/6 [00:40<00:00,  6.74s/it]\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://116.101.122.180:5200/{index}*/_search\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": \"ApiKey\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "index_arr = [\"kong-access-\", \"metricbeat-\", \"traces-apm\", \"apm-\", \"logs-apm\", \"metrics-apm\"]\n",
    "\n",
    "for index in tqdm(index_arr):\n",
    "    url = base_url.format(index=index)\n",
    "    data = {\n",
    "        \"from\": 0,\n",
    "        \"size\": 500,\n",
    "        \"query\": queries[f\"{index}\"],\n",
    "        \"sort\": [\n",
    "            {\n",
    "                \"@timestamp\": {\n",
    "                    \"order\": \"asc\"\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    response = requests.get(\n",
    "        url, headers=headers,\n",
    "        json=data, verify=False\n",
    "    )\n",
    "    data = response.json()\n",
    "    with open(f\"./logs/{index}.json\", \"w\") as json_file:\n",
    "        json.dump(data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "with open('/home/aiteam/Documents/longvu02/example/logs/logs-apm-v2.json', 'r') as file:  # Replace with your actual file path\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extracting relevant fields from the nested structure\n",
    "extracted_data = []\n",
    "\n",
    "for hit in data['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    error_info = source.get('error', {})\n",
    "    stacktrace = error_info.get('stacktrace', [])\n",
    "    \n",
    "    # Prepare a dictionary for each record\n",
    "    record = {\n",
    "        'INFO message': source.get('message', ''),\n",
    "        'WARD message': '',  # Assuming WARD message is not present in the provided structure\n",
    "        'ERROR message': error_info.get('message', ''),\n",
    "        'Stack trace': '\\n'.join([f\"{item['classname']} - {item['filename']}:{item['line']['number']} - {item['function']}\" for item in stacktrace]),\n",
    "        'Error code': error_info.get('type', ''),  # Assuming type as Error code\n",
    "        'Error cause': error_info.get('exception', [{}])[0].get('message', '')  # Get first exception message as Error cause\n",
    "    }\n",
    "    \n",
    "    extracted_data.append(record)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Print the first 10 rows of the DataFrame\n",
    "print(df.head(10))\n",
    "df.to_csv('/home/aiteam/Documents/longvu02/example/csv/logs_apm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from a file\n",
    "with open('/home/aiteam/Documents/longvu02/example/logs/logs-apm-v2.json', 'r') as file:  # Replace with your actual file path\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extracting relevant fields from the nested structure\n",
    "extracted_data = []\n",
    "\n",
    "for hit in data['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    error_info = source.get('error', {})\n",
    "    stacktrace = error_info.get('stacktrace', [])\n",
    "    \n",
    "    # Prepare a dictionary for each record\n",
    "    record = {\n",
    "        'INFO message': source.get('message', ''),\n",
    "        'WARD message': '',  # Assuming WARD message is not present in the provided structure\n",
    "        'ERROR message': error_info.get('message', ''),\n",
    "        'Stack trace': '\\n'.join([f\"{item['classname']} - {item['filename']}:{item['line']['number']} - {item['function']}\" for item in stacktrace]),\n",
    "        'Error code': error_info.get('type', ''),  # Assuming type as Error code\n",
    "        'Error cause': error_info.get('exception', [{}])[0].get('message', '')  # Get first exception message as Error cause\n",
    "    }\n",
    "    \n",
    "    extracted_data.append(record)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Print the first 10 rows of the DataFrame\n",
    "print(df.head(10))\n",
    "df.to_csv('/home/aiteam/Documents/longvu02/example/csv/metrics_apm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('/home/aiteam/Documents/longvu02/example/logs/traces-apm-v2.json', 'r') as file:  # Replace with your actual file path\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "\n",
    "# Prepare a list to hold the extracted records\n",
    "extracted_data = []\n",
    "\n",
    "# Iterate through each hit in the JSON data\n",
    "for hit in data['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    \n",
    "    # Extract relevant fields\n",
    "    transaction = source.get('transaction', {})\n",
    "    \n",
    "    # Ensure duration is accessed correctly and converted to seconds\n",
    "    duration_us = transaction.get('duration', {}).get('us', 0)  # Default to 0 if not found\n",
    "    \n",
    "    record = {\n",
    "        'transactions': transaction.get('name', ''),\n",
    "        'spans': source.get('span', {}).get('name', ''),\n",
    "        'transaction start time': source.get('@timestamp', ''),\n",
    "        'transaction end time': (int(transaction.get('@timestamp', 0)) + duration_us) / 1_000_000,  # Convert microseconds to seconds\n",
    "        'trace path': source.get('trace', {}).get('id', '')\n",
    "    }\n",
    "    \n",
    "    extracted_data.append(record)\n",
    "\n",
    "# Create a DataFrame from the extracted data\n",
    "df = pd.DataFrame(extracted_data)\n",
    "\n",
    "# Print the first 10 rows of the DataFrame\n",
    "print(df.head(10))\n",
    "df.to_csv('/home/aiteam/Documents/longvu02/example/csv/traces_apm.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
